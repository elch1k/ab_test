**A brief preface:** This repository has been transformed from a single project into a collection of projects and resources related to A/B testing, statistics, and probability.

`AB_test_project.ipynb` contains a report of an A/B test analysis, comparing two groups with a continuous metric (average customer check) using both bootstrap and non-parametric Mann-Whitney U tests to determine significance. This project utilizes [Kaggle](https://www.kaggle.com/datasets/sergylog/ab-test-data) data, which presented significant quality issues and did not adhere to proper splitter and test design principles. Consequently, extensive data preprocessing was necessary. This allowed for the implementation of A/B testing approaches, which you can explore further via the provided [link](https://github.com/elch1k/ab_test/blob/main/AB_test_project.ipynb).

`probability_monte_carlo.ipynb` contains statistical assessments and probability tasks addressed using Monte Carlo simulation techniques. You can find more details by following the [link](https://github.com/elch1k/ab_test/blob/main/probability_monte_carlo.ipynb).

The `statistics_multiple_hypotesis.ipynb` notebook explores the multiple hypothesis problem and methods to address it, specifically using Bonferroni correction and the Benjamini-Hochberg method on simulated data. Unfortunately, Hierarchical Modeling, another technique for handling multiple hypotheses, was not implemented (can find information about Hierarchical Modeling with the older `pymc` package in this [article](https://domino.ai/blog/ab-testing-with-hierarchical-models-in-python)). The notebook also features the Bucketing method, designed to optimize bootstrap processing for large datasets. Furthermore, a Monte Carlo approach was utilized to select a valid practical criterion and determine the most suitable criterion for specific tasks. The Monte Carlo section of the notebook also includes a script to identify the best data distribution model for your data. The full report is available via this [link](https://github.com/elch1k/ab_test/blob/main/statistics_multiple_hypotesis.ipynb).

The `djinni_AB_test.ipynb` notebook presents a real-world A/B testing case study. The primary objective was to increase the percentage of applications read by recruiters and, consequently, the percentage of applications answered by recruiters. A guardrail metric was also monitored: the ratio of read to answered applications. This work involved EDA, A/B testing using bootstrap techniques, and classical statistical tests. Following this, a cohort analysis (grouping) was implemented, categorizing recruiters by the number of applications they received. Differences within these groups were then further examined using bootstrap analysis and ANOVA tests. Report available [here](https://github.com/elch1k/ab_test/blob/main/djinni_AB_test.ipynb).

*New notebooks and resources are coming soon!*
